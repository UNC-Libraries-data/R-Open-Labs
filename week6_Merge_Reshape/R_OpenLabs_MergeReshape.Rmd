---
title: "R Open Labs: Joining and Reshaping with tidyr"
author:
- name: University of North Carolina at Chapel Hill
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: false
    theme: spacelab
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data and other downloads

[Download data](data/brazilian-ecommerce-subset.zip)

Data derived from [Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/olistbr/brazilian-ecommerce) provided on Kaggle.com under a [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license.



```{r message=FALSE, warning=FALSE}
library(tidyverse)
```


## Today
This workshop covers topics from:

[Chapter 12](http://r4ds.had.co.nz/tidy-data.html)

[Chapter 13](http://r4ds.had.co.nz/relational-data.html)

* Joining / Merging datasets
    + `bind_rows` and `bind_cols`
    + `inner_join`
    + "Outer Joins" - `full_join`,`left_join`,`right_join`
* Reshaping data
    + `pivot_longer`
    + `pivot_wider`

## Motivation

Most weeks so far, we've usually worked with a single dataset.  This week, we'll work with methods to combine multiple datasets or create reshaped datasets.  During a project, we may need to merge or reshape our datasets in many different ways through the course of analysis.

When using data about the same observational units collected by different sources, we often need to combine separate datasets before analysis.  For example, we might create a dataset about all of the countries of the world with data from the UN, the World Bank, and the World Health Organization. Sometimes we will need to *merge* or *join* these datasets into a single dataframe for analysis.  In other cases, we may simply need to add observations to an existing dataset (e.g. if each country is published separately in the same format.)

In other cases, we might need to reshape data we already have to make it more appropriate for other software, for analysis, or easier to use within R.  If you're planning to export data from R to another software package, you may need a particular format.  For example, mapping software like ArcGIS needs each row of a dataset to represent a geographic location.  

## Merging / Joining Dataframes

#### Appending

Sometimes we'll have two datasets with similar columns that we need to combine. Essentially, we are stacking the rows of those datasets on top of each other. We can add rows in `dplyr` with `bind_rows`:

```{r}
a0 <- data.frame("id"=c(1,2),
                 "val"=rnorm(2,0,1))

a1 <- data.frame("id"=c(3,4),
                 "val"=rnorm(2,0,1),
                 "other"=c("c","d"))

bind_rows(a0,a1)
```

When we refer to merging or joining, we usually do not mean appending or adding observations to a dataset in this way. Instead, merging usuallly intends to add columns or variables to our dataframe.  Using `bind_rows` in this context is unhelpful.

```{r}
b0 <- data.frame("name"=c("John","Jane"),
                 "year"=c(1993,1996))

b1 <- data.frame("name"=c("Jane","John"),
                 "ct"=c(6,3))

bind_cols(b0,b1)
```

Instead, we want to add columns while making sure certain identifying variables, often called *keys* (e.g. `name` and `name1` above) line up to make sure each row represents information about a single observational unit.

### Merging

#### Keys

To properly line up observations between two datasets, we need a common variable (or group of variables) that uniquely identifies an observation in at least one of the datasets, and identifies it in the same way across both datasets.  This variable is usually called a "key".  In our example above, `b0` and `b1` have the key "name".

```{r}
print(b0)
print(b1)
```

Once we have matching key variable(s) in our datasets, we can join our datasets into consistent observations.  There are two major categories of joins - "Inner Joins" and "Outer Joins".

### Types of Joins

We need several different types of joins to facillitate the different ways datasets are organized.

<center>
| Want to keep | Function|
|--------------------------------------------|-------|
|**Inner Joins**| |
|Only the rows in both datasets |`inner_join()`|
|**Outer Joins**| |
|All of the rows |`full_join()`|
|All of the rows in the first (left) dataset, only the matches from the second (right dataset) |`left_join()`|
|All of the rows in the second (left) dataset, only the matches from the first (right dataset) |`right_join()`|
</center>

The join types can be represented as Venn Diagrams:

![](https://r4ds.had.co.nz/diagrams/join-venn.png)
 <center>*Join Types from R for Data Science 13.4.3*</center> 

We can apply each to updated `b0` and `b1` datasets:

```{r}
b0 <- data.frame("name"=c("John","Jane","Jack"),
                 "year"=c(1993,1993,1985))

b1 <- data.frame("person"=c("Jane","John","Jill"),
                 "ct"=c(6,3,9))
print(b0)
print(b1)
```

#### Inner Join

##### `inner_join`

```{r warning=FALSE}
inner_join(b0,b1,by=c("name"="person"))
```

#### Outer Joins

##### `full_join`

```{r warning=FALSE}
full_join(b0,b1,by=c("name"="person"))
```

##### `left_join`

```{r warning=FALSE}
left_join(b0,b1,by=c("name"="person"))
```

##### `right_join`

```{r warning=FALSE}
right_join(b0,b1,by=c("name"="person"))
```

### Extensions

Note: All of these join functions come from the `dplyr` package, so we can use them with pipes ( %>% ).

#### Multiple Keys

In some cases, we may need multiple keys to uniquely identify an observation:

```{r}
multi0 <- data.frame("name"=c("Jane","John","John","Jane"),
                     "year"=c(1990,1990,1991,1991),
                     "state"=c("NC","VA","VA","NY"))
multi1 <- data.frame("person"=c("Jane","John","Jane","John"),
                     "year"=c(1990,1990,1991,1991),
                     "ct"=c(6,3,9,8))

multijoined <- inner_join(multi0,multi1,
                          by=c("name"="person","year"="year"))
```


#### Many-to-one and One-to-many Joins

If we only specify enough key variables to uniquely identify observations in one dataset and not the other, each unique value from the first dataset will be joined to each instance of that value in the other dataset.

```{r}
statedata <- data.frame("state"=c("NC","VA","NY"),
                        "region"=c("Southeast","Southeast","Northeast"))
inner_join(statedata,multijoined,by=c("state"="state"))
```

Note: We can equivalently omit `by=c("state"="state")` since the key variables have the same name here.

## Reshaping with `tidyr`

Once we have a single dataset, we may still need to change its shape.  This process can be particularly confusing since the names for the steps and goals of this process have changed many times in recent years (e.g. "reshape wide", "reshape long", "melt", "cast", "wide data", "long data", "tidy data", "gather", "spread").  We'll stick to the `tidyverse` terminology and avoid "wide" and "long", and focus on operations instead.

**Note**: Hadley Wickham's [Tidy Data](http://vita.had.co.nz/papers/tidy-data.html) provides more discussion of what "Tidy Data" entails and why it's useful in data analysis.

#### Use Case: Making `ggplot` easier

Why reshape when we have perfectly good data?  Sometimes R's own functions are more convenient with reshaped data.

```{r}
set.seed(123)
df0 <- data.frame(year=c(2000,2001,2002),a=runif(3,0,20),b=runif(3,0,20))
print(df0)
```

We can use `ggplot2` to generate a line plot for our two data columns, `a` and `b`:

```{r}
ggplot(data=df0,aes(x=year))+
  geom_line(aes(y=a),color="red")+
  geom_line(aes(y=b),color="blue")+theme_bw()
```

However if we had the data available in a longer format, we could plot them with less code.

```{r}
df1 <- data.frame(year=c(df0$year,df0$year),
                  v=c("a","a","a","b","b","b"),
                  value=c(df0$a,df0$b))
print(df1)
```

```{r}
ggplot(data=df1,aes(x=year,y=value,color=v))+geom_line()+theme_bw()
```

We can move back and forth between `df0` and `df1` formats with `tidyr`'s `gather` and `spread` functions.

### `gather`

First, let's create a small example dataset.

```{r}
library(tidyr) #install if necessary
set.seed(123)
raw <- data.frame(
  city=c("Raleigh","Durham","Chapel Hill"),
  x2000=rnorm(3,0,1),
  x2001=rnorm(3,0,1),
  x2002=rnorm(3,0,1),
  x2003=rnorm(3,0,1)
)
print(raw)
```

x2000 through x2003 represent something measured in 2000 to 2003, since R data.frames cannot have labels that start with numbers.

It might be useful to have the year stored as a column instead of as column names.  We can use the `gather` function to do this.

`gather` takes four main arguments:

1. data: this **must** be a data frame.
2. key: the **name** of a new column, whose values will be the **names of the columns** we're gathering.
3. value: the **name** of another new column, whose values will be the **values from the columns** we're gathering.
4. columns: the list of columns to gather.  This can be specified in two different ways:
    + a vector of column names
    + a minus sign before a column name or vector of column names to **not** gather
    
The output of gather will generally be taller or longer than input dataset.  Sometimes this is called "long data" or "long format", but that can be misleading because there are usually varying degrees of longness or wideness for a dataset.

```{r warning=FALSE}
gathered <- raw %>% 
  gather(key="year",value="value",-city) %>% 
  mutate(year=str_replace(year,"x","")) 
print(gathered)
```

It's often useful to think about how transformations like gather change the effective observational unit of the dataset.  Assuming rows contain observations, this dataset started with city-level observations.  The transformed data frame `gathered` now observes one city in a given year in each row.

tidyr functions can take column names with or without quotes (see city in the first line above).  See the alternative below.

```{r}
gathered <- raw %>% 
  gather(key=year,value=value,c(x2000,x2001,x2002,x2003)) %>% 
  mutate(year=str_replace(year,"x","")) 
print(gathered)
```

### `spread`

We can reverse this transformation with `spread`.  This time we'll create a separate column for each city.

`spread` takes three essential arguments:

1. data
2. key: the **column** whose values we'll use to create new columns.
3. value: another **column** whose values will be rearranged into the new columns based on the values in the key column.

```{r}
ungathered <- gathered %>% spread(key=city,value=value)
print(ungathered)
```

This might be a useful step to determine which cities are most closely correlated as part of an Exploratory Data Analysis.

```{r message=FALSE}
library(GGally)
ungathered %>% select("Chapel Hill","Durham","Raleigh") %>% ggpairs()
```

## Exercises:

All of today's exercises involve the datasets included in [brazilian-commerce-subset.zip.](data/brazilian-ecommerce-subset.zip)

1. Read olist_public_dataset_v2.csv into R. Explore the dataset. If necessary, refer to the metadata provided [here](https://www.kaggle.com/olistbr/brazilian-ecommerce).

2. Read product_category_name_translation.csv into R.  Merge this dataframe into olist_public_dataset_v2.csv using `product_category_name` as the key variable.
Let's explore which products are most frequently purchased together:

3. Use `group_by` and `summarize` to find the total `order_items_qty` for each `product_category_name_english` in each `customer state`. [Review](https://unc-libraries-data.github.io/R-Open-Labs/week3_Transformations/R_OpenLabs_3_Transformations.html)

4. Use `spread` to create a new dataframe with a row for each `customer_state` and a column for each `product_category_name_english`.  Name this dataframe `products`.

5. Run these two lines of code (make sure your dataframe from step 4 is called `products`!):

```
products <- ungroup(products) #remove grouping 
products[is.na(products)] <- 0 #replace missing data with zeroes
```

6. Use `ggpairs` or other Exploratory Data Analysis techniques to look for relationships between purchases of `small_appliances`,`consoles_games`,`air_conditioning`, and `construction_tools_safety`. (Remember to run `library(GGally)` before using `ggpairs`).

7. Repeat problems 3-6 with `order_products_value` (i.e. the amount spent vs the quantity purchased).  Do you see different patterns?  Explore other product categories.

8. Use `gather` and then `spread` to convert your `products` dataframe to one where each row is a different `product_category_name_english` and each column represents a different `customer_state`.  

9. Choose 5 states. Which of these states have the most similar patterns of spending (as measured by correlation)?

## Feedback
[Let us know what you think of this lesson!](https://unc.az1.qualtrics.com/jfe/form/SV_8e1zRY2rlFUYBMx)